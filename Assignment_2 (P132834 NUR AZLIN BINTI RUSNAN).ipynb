{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a1c7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1d12b",
   "metadata": {},
   "source": [
    "#### Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e14e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/User/UKM - Nur Azlin Binti Rusnan/Sem 2/Machine Learning/Assignment 2/Assignment2_2023_data.txt\", names=[\n",
    "    'Subject id', 'Jitter (local)', 'Jitter (local, absolute)', 'Jitter (rap)', 'Jitter (ppq5)', 'Jitter (ddp)',\n",
    "    'Shimmer (local)', 'Shimmer (local, dB)', 'Shimmer (apq3)', 'Shimmer (apq5)', 'Shimmer (apq11)', 'Shimmer (dda)',\n",
    "    'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch',\n",
    "    'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period',\n",
    "    'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'UPDRS score', 'Class Information'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f419a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject id</th>\n",
       "      <th>Jitter (local)</th>\n",
       "      <th>Jitter (local, absolute)</th>\n",
       "      <th>Jitter (rap)</th>\n",
       "      <th>Jitter (ppq5)</th>\n",
       "      <th>Jitter (ddp)</th>\n",
       "      <th>Shimmer (local)</th>\n",
       "      <th>Shimmer (local, dB)</th>\n",
       "      <th>Shimmer (apq3)</th>\n",
       "      <th>Shimmer (apq5)</th>\n",
       "      <th>...</th>\n",
       "      <th>Maximum pitch</th>\n",
       "      <th>Number of pulses</th>\n",
       "      <th>Number of periods</th>\n",
       "      <th>Mean period</th>\n",
       "      <th>Standard deviation of period</th>\n",
       "      <th>Fraction of locally unvoiced frames</th>\n",
       "      <th>Number of voice breaks</th>\n",
       "      <th>Degree of voice breaks</th>\n",
       "      <th>UPDRS score</th>\n",
       "      <th>Class Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.488</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.794</td>\n",
       "      <td>2.699</td>\n",
       "      <td>8.334</td>\n",
       "      <td>0.779</td>\n",
       "      <td>4.517</td>\n",
       "      <td>4.609</td>\n",
       "      <td>...</td>\n",
       "      <td>187.576</td>\n",
       "      <td>160</td>\n",
       "      <td>159</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.059</td>\n",
       "      <td>5.864</td>\n",
       "      <td>0.642</td>\n",
       "      <td>2.058</td>\n",
       "      <td>3.180</td>\n",
       "      <td>...</td>\n",
       "      <td>234.505</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>2.247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.220</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.670</td>\n",
       "      <td>2.196</td>\n",
       "      <td>8.719</td>\n",
       "      <td>0.875</td>\n",
       "      <td>4.347</td>\n",
       "      <td>5.166</td>\n",
       "      <td>...</td>\n",
       "      <td>211.442</td>\n",
       "      <td>1431</td>\n",
       "      <td>1427</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>10.656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.502</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>1.156</td>\n",
       "      <td>1.634</td>\n",
       "      <td>3.469</td>\n",
       "      <td>13.513</td>\n",
       "      <td>1.273</td>\n",
       "      <td>5.263</td>\n",
       "      <td>8.771</td>\n",
       "      <td>...</td>\n",
       "      <td>220.230</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.509</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.715</td>\n",
       "      <td>1.539</td>\n",
       "      <td>5.145</td>\n",
       "      <td>9.112</td>\n",
       "      <td>1.040</td>\n",
       "      <td>3.102</td>\n",
       "      <td>4.927</td>\n",
       "      <td>...</td>\n",
       "      <td>225.162</td>\n",
       "      <td>117</td>\n",
       "      <td>114</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>18.182</td>\n",
       "      <td>1</td>\n",
       "      <td>13.318</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2.470</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.358</td>\n",
       "      <td>1.341</td>\n",
       "      <td>4.075</td>\n",
       "      <td>10.696</td>\n",
       "      <td>1.256</td>\n",
       "      <td>5.262</td>\n",
       "      <td>7.076</td>\n",
       "      <td>...</td>\n",
       "      <td>202.812</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>23.214</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.583</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.864</td>\n",
       "      <td>2.303</td>\n",
       "      <td>9.057</td>\n",
       "      <td>1.070</td>\n",
       "      <td>3.794</td>\n",
       "      <td>5.158</td>\n",
       "      <td>...</td>\n",
       "      <td>200.638</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>4.348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.920</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.926</td>\n",
       "      <td>1.031</td>\n",
       "      <td>2.777</td>\n",
       "      <td>10.184</td>\n",
       "      <td>1.108</td>\n",
       "      <td>3.650</td>\n",
       "      <td>4.611</td>\n",
       "      <td>...</td>\n",
       "      <td>201.921</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>33.929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2.257</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.239</td>\n",
       "      <td>1.530</td>\n",
       "      <td>3.716</td>\n",
       "      <td>8.044</td>\n",
       "      <td>0.877</td>\n",
       "      <td>3.449</td>\n",
       "      <td>4.239</td>\n",
       "      <td>...</td>\n",
       "      <td>210.523</td>\n",
       "      <td>107</td>\n",
       "      <td>104</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>15.152</td>\n",
       "      <td>2</td>\n",
       "      <td>9.810</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.951</td>\n",
       "      <td>2.550</td>\n",
       "      <td>7.200</td>\n",
       "      <td>0.823</td>\n",
       "      <td>2.480</td>\n",
       "      <td>3.826</td>\n",
       "      <td>...</td>\n",
       "      <td>203.133</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject id  Jitter (local)  Jitter (local, absolute)  Jitter (rap)  \\\n",
       "0           1           1.488                  0.000090         0.900   \n",
       "1           1           0.728                  0.000038         0.353   \n",
       "2           1           1.220                  0.000074         0.732   \n",
       "3           1           2.502                  0.000123         1.156   \n",
       "4           1           3.509                  0.000167         1.715   \n",
       "5           1           2.470                  0.000126         1.358   \n",
       "6           1           1.583                  0.000082         0.768   \n",
       "7           1           1.920                  0.000099         0.926   \n",
       "8           1           2.257                  0.000119         1.239   \n",
       "9           1           1.594                  0.000085         0.850   \n",
       "\n",
       "   Jitter (ppq5)  Jitter (ddp)  Shimmer (local)  Shimmer (local, dB)  \\\n",
       "0          0.794         2.699            8.334                0.779   \n",
       "1          0.376         1.059            5.864                0.642   \n",
       "2          0.670         2.196            8.719                0.875   \n",
       "3          1.634         3.469           13.513                1.273   \n",
       "4          1.539         5.145            9.112                1.040   \n",
       "5          1.341         4.075           10.696                1.256   \n",
       "6          0.864         2.303            9.057                1.070   \n",
       "7          1.031         2.777           10.184                1.108   \n",
       "8          1.530         3.716            8.044                0.877   \n",
       "9          0.951         2.550            7.200                0.823   \n",
       "\n",
       "   Shimmer (apq3)  Shimmer (apq5)  ...  Maximum pitch  Number of pulses  \\\n",
       "0           4.517           4.609  ...        187.576               160   \n",
       "1           2.058           3.180  ...        234.505               170   \n",
       "2           4.347           5.166  ...        211.442              1431   \n",
       "3           5.263           8.771  ...        220.230                94   \n",
       "4           3.102           4.927  ...        225.162               117   \n",
       "5           5.262           7.076  ...        202.812                74   \n",
       "6           3.794           5.158  ...        200.638                85   \n",
       "7           3.650           4.611  ...        201.921                71   \n",
       "8           3.449           4.239  ...        210.523               107   \n",
       "9           2.480           3.826  ...        203.133               113   \n",
       "\n",
       "   Number of periods  Mean period  Standard deviation of period  \\\n",
       "0                159     0.006065                      0.000416   \n",
       "1                169     0.005181                      0.000403   \n",
       "2               1427     0.006071                      0.000474   \n",
       "3                 92     0.004910                      0.000320   \n",
       "4                114     0.004757                      0.000380   \n",
       "5                 73     0.005118                      0.000187   \n",
       "6                 84     0.005199                      0.000245   \n",
       "7                 70     0.005137                      0.000215   \n",
       "8                104     0.005282                      0.000348   \n",
       "9                112     0.005335                      0.000332   \n",
       "\n",
       "   Fraction of locally unvoiced frames  Number of voice breaks  \\\n",
       "0                                0.000                       0   \n",
       "1                                2.247                       0   \n",
       "2                               10.656                       1   \n",
       "3                                0.000                       0   \n",
       "4                               18.182                       1   \n",
       "5                               23.214                       0   \n",
       "6                                4.348                       0   \n",
       "7                               33.929                       0   \n",
       "8                               15.152                       2   \n",
       "9                                0.000                       0   \n",
       "\n",
       "   Degree of voice breaks  UPDRS score  Class Information  \n",
       "0                   0.000           23                  1  \n",
       "1                   0.000           23                  1  \n",
       "2                   0.178           23                  1  \n",
       "3                   0.000           23                  1  \n",
       "4                  13.318           23                  1  \n",
       "5                   0.000           23                  1  \n",
       "6                   0.000           23                  1  \n",
       "7                   0.000           23                  1  \n",
       "8                   9.810           23                  1  \n",
       "9                   0.000           23                  1  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107521a2",
   "metadata": {},
   "source": [
    "#### Step 2: Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4595b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "\n",
      "Subject id                             0\n",
      "Jitter (local)                         0\n",
      "Jitter (local, absolute)               0\n",
      "Jitter (rap)                           0\n",
      "Jitter (ppq5)                          0\n",
      "Jitter (ddp)                           0\n",
      "Shimmer (local)                        0\n",
      "Shimmer (local, dB)                    0\n",
      "Shimmer (apq3)                         0\n",
      "Shimmer (apq5)                         0\n",
      "Shimmer (apq11)                        0\n",
      "Shimmer (dda)                          0\n",
      "AC                                     0\n",
      "NTH                                    0\n",
      "HTN                                    0\n",
      "Median pitch                           0\n",
      "Mean pitch                             0\n",
      "Standard deviation                     0\n",
      "Minimum pitch                          0\n",
      "Maximum pitch                          0\n",
      "Number of pulses                       0\n",
      "Number of periods                      0\n",
      "Mean period                            0\n",
      "Standard deviation of period           0\n",
      "Fraction of locally unvoiced frames    0\n",
      "Number of voice breaks                 0\n",
      "Degree of voice breaks                 0\n",
      "UPDRS score                            0\n",
      "Class Information                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values before handling:\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e8f67",
   "metadata": {},
   "source": [
    "#### Step 3: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e13ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-significant columns\n",
    "df = df.drop(['Subject id', 'Class Information'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "354439c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(['UPDRS score'], axis=1)\n",
    "y = df['UPDRS score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776e69f",
   "metadata": {},
   "source": [
    "- We dropped 'Subject id', 'UPDRS score', 'Class Information' from the model. 'Subject id' did not significantly impact the MLR model's performance, 'UPDRS score' was designated as the target variable, and 'Class Information' is a categorical variable indicating the presence or absence of Parkinson’s disease, which is not directly relevant for predicting the continuous UPDRS score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2342c34",
   "metadata": {},
   "source": [
    "#### Step 4: Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f53c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c6b8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f76d8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59120ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5433c1c",
   "metadata": {},
   "source": [
    "- We run this step to ensure that all features contribute equally to the model. This is important for the stability and efficiency of the training process in Multiple Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21aa9d3",
   "metadata": {},
   "source": [
    "#### Step 5: Train the Multiple Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0392fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f5d866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Multiple Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2160d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the UPDRS scores for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae98a93",
   "metadata": {},
   "source": [
    "#### Step 6: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e98e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72faa29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "MLR_mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "cv_scores_lr = cross_val_score(model, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5bf71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 214.1882036951883 \n",
      "R2: 0.12217816256786163 \n",
      "CV R2: -0.4488644603972037\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression - MSE:\", MLR_mse, \"\\nR2:\", r2, \"\\nCV R2:\", cv_scores_lr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06271c0c",
   "metadata": {},
   "source": [
    "MSE measures the average of the squares of the errors that is, the difference between the actual values and the predicted values. In this context, it means that on average, the square of the errors between the predicted and actual UPDRS scores is about 214.19.\n",
    "\n",
    "A lower MSE indicates better model performance. In this case, an MSE of 214.19 suggests that there is a substantial error in the predictions. This might imply that the model is not performing very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f54ef",
   "metadata": {},
   "source": [
    "R-squared is a statistical measure of how close the data are to the fitted regression line. It represents the proportion of the variance in the dependent variable (UPDRS scores) that is predictable from the independent variables (features).\n",
    "\n",
    "R² ranges from 0 to 1. An R² value of 0.122 means that only about 12.2% of the variability in UPDRS scores is explained by the model. This indicates that the model is not capturing a significant portion of the variance and might not be a good predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d1f86",
   "metadata": {},
   "source": [
    "**MLR Model Performance:** \n",
    "\n",
    "The high MSE and low R² values indicate that the model is not performing well. This suggests that either the features are not good predictors or that the linear model is not suitable for this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17ab65",
   "metadata": {},
   "source": [
    "## Steps to find the best model by running test with Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccecc42c",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ef665e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE: 212.5192075426505 \n",
      "R2: 0.12901832110139522 \n",
      "CV R2: -0.4090502056005335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Train and evaluate Ridge Regression\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores_ridge = cross_val_score(ridge, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Output\n",
    "print(\"Ridge Regression - MSE:\", mse_ridge, \"\\nR2:\", r2_ridge, \"\\nCV R2:\", cv_scores_ridge.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c8aa1",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea0cef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - MSE: 212.9674508530177 \n",
      "R2: 0.12718125556961113 \n",
      "CV R2: -0.4104392544094592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.487e+04, tolerance: 1.827e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.782e+04, tolerance: 1.848e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.033e+04, tolerance: 2.037e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.640e+04, tolerance: 2.251e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.379e+04, tolerance: 2.251e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Train and evaluate Lasso Regression\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores_lasso = cross_val_score(lasso, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Output\n",
    "print(\"Lasso Regression - MSE:\", mse_lasso, \"\\nR2:\", r2_lasso, \"\\nCV R2:\", cv_scores_lasso.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64674b8e",
   "metadata": {},
   "source": [
    "### **Linear, Ridge and Lasso Regression Model Performance**\n",
    "\n",
    "**Performance Metrics**\n",
    "\n",
    "For Linear Regression, the Mean Squared Error (MSE) is 214.19, the R-squared (R²) is 0.1222, and the Cross-Validation R² (CV R²) is -0.4489. For Ridge Regression, the Mean Squared Error (MSE) is 212.51, the R-squared (R²) is 0.1290, and the Cross-Validation R² (CV R²) is -0.4484. For Lasso Regression, the Mean Squared Error (MSE) is 212.95, the R-squared (R²) is 0.1272, and the Cross-Validation R² (CV R²) is -0.4340.\n",
    "\n",
    "**Comparison**\n",
    "\n",
    "When comparing Mean Squared Error (MSE) values, Ridge Regression has the lowest MSE (212.51), followed closely by Lasso Regression (212.95), and then Linear Regression (214.19). Lower MSE values indicate better predictive accuracy. In terms of R-squared (R²), Ridge Regression has the highest R² (0.1290), followed by Lasso Regression (0.1272), and then Linear Regression (0.1222). Higher R² values indicate a better fit to the data. For Cross-Validation R² (CV R²) scores, all models have negative values, indicating potential issues with generalization to unseen data. However, Lasso Regression has the least negative CV R² (-0.4340), suggesting it might be slightly more robust in terms of generalization compared to Ridge and Linear Regression.\n",
    "\n",
    "Based on the comparison of MSE, R², and CV R², Ridge Regression appears to be the best model among the three. It has the lowest MSE and the highest R², indicating that it fits the data slightly better than Linear and Lasso Regression. However, the differences are relatively small, and all models have challenges with generalization as indicated by the negative CV R² scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10171e36",
   "metadata": {},
   "source": [
    "MSE value for Linear, Ridge and Lasso are all consider high. Lets see if Random Forest can improve the prediction performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fef8f",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b349ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of Random Forest model: 195.1649466346154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize Random Forest Regressor with default parameters\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Mean Squared Error of Random Forest model:\", mse_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12e99d",
   "metadata": {},
   "source": [
    "The Random Forest model with default parameters performed better than the initial MLR model, reducing the MSE from 214.19 to 196.51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f54f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: (200, 193.3496373798077, 0.20758225232086702)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/User/UKM - Nur Azlin Binti Rusnan/Sem 2/Machine Learning/Assignment 2/Assignment2_2023_data.txt\", names=[\n",
    "    'Subject id', 'Jitter (local)', 'Jitter (local, absolute)', 'Jitter (rap)', 'Jitter (ppq5)', 'Jitter (ddp)',\n",
    "    'Shimmer (local)', 'Shimmer (local, dB)', 'Shimmer (apq3)', 'Shimmer (apq5)', 'Shimmer (apq11)', 'Shimmer (dda)',\n",
    "    'AC', 'NTH', 'HTN', 'Median pitch', 'Mean pitch', 'Standard deviation', 'Minimum pitch', 'Maximum pitch',\n",
    "    'Number of pulses', 'Number of periods', 'Mean period', 'Standard deviation of period',\n",
    "    'Fraction of locally unvoiced frames', 'Number of voice breaks', 'Degree of voice breaks', 'UPDRS score', 'Class Information'\n",
    "])\n",
    "\n",
    "X = data.drop(columns=['Subject id', 'UPDRS score', 'Class Information'])\n",
    "y = data['UPDRS score']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "n_estimators_values = [100, 200, 300]\n",
    "results = []\n",
    "\n",
    "for n in n_estimators_values:\n",
    "    rf_model = RandomForestRegressor(n_estimators=n, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append((n, mse, r2))\n",
    "\n",
    "best_n = min(results, key=lambda x: x[1])  # Get the parameters with the best (lowest) MSE\n",
    "print(\"Best n_estimators:\", best_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba0dcdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: (10, 190.94717165434253, 0.21742843825040026)\n"
     ]
    }
   ],
   "source": [
    "# Define values for max_depth to test\n",
    "max_depth_values = [10, 20, 30, None]\n",
    "results_depth = []\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    rf_model = RandomForestRegressor(n_estimators=200, max_depth=depth, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results_depth.append((depth, mse, r2))\n",
    "\n",
    "best_depth = min(results_depth, key=lambda x: x[1])  # Get the parameters with the best (lowest) MSE\n",
    "print(\"Best max_depth:\", best_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63eb8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best min_samples_split: (2, 190.94717165434253, 0.21742843825040026)\n"
     ]
    }
   ],
   "source": [
    "# Define values for min_samples_split to test\n",
    "min_samples_split_values = [2, 5, 10]\n",
    "results_split = []\n",
    "\n",
    "for split in min_samples_split_values:\n",
    "    rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=split, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results_split.append((split, mse, r2))\n",
    "\n",
    "best_split = min(results_split, key=lambda x: x[1])  # Get the parameters with the best (lowest) MSE\n",
    "print(\"Best min_samples_split:\", best_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ada32f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best min_samples_leaf: (4, 186.62558429747136, 0.23513988868877633)\n"
     ]
    }
   ],
   "source": [
    "# Define values for min_samples_leaf to test\n",
    "min_samples_leaf_values = [1, 2, 4]\n",
    "results_leaf = []\n",
    "\n",
    "for leaf in min_samples_leaf_values:\n",
    "    rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=2, min_samples_leaf=leaf, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results_leaf.append((leaf, mse, r2))\n",
    "\n",
    "best_leaf = min(results_leaf, key=lambda x: x[1])  # Get the parameters with the best (lowest) MSE\n",
    "print(\"Best min_samples_leaf:\", best_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25413855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186.62558429747136, 0.23513988868877633)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "final_rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42\n",
    ")\n",
    "final_rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "final_y_pred = final_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the final model\n",
    "final_mse = mean_squared_error(y_test, final_y_pred)\n",
    "final_r2 = r2_score(y_test, final_y_pred)\n",
    "\n",
    "final_mse, final_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb982524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "mse_values = [MLR_mse, mse_ridge, mse_lasso, mse_rf, final_mse]\n",
    "model_names = ['Initial MLR', 'Ridge', 'Lasso', 'Random Forest', 'Tuned RF']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(model_names, mse_values, color='blue')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('MSE Comparison of Different Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129ca79",
   "metadata": {},
   "source": [
    "### **Overall Model Performance:** \n",
    "\n",
    "The best Multiple Linear Regression (MLR) model was achieved using Ridge regression, with an MSE of 212.51. This indicates that Ridge regression provided a slight improvement over the initial MLR model (MSE of 214.19) and Lasso regression (MSE of 212.95). However, the Random Forest model, especially after hyperparameter tuning, significantly outperformed all MLR models, achieving a much lower MSE of 186.62. This demonstrates that while Ridge regression is the best MLR model for predicting UPDRS scores, more complex models like Random Forests offer superior predictive performance for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
